{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArmenKhachatrianProblemSet5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEBq12vj18q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from progressbar import progressbar\n",
        "import scipy.stats\n",
        "import statsmodels.stats.power as power\n",
        "import statsmodels.formula.api as sfa\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({\n",
        "    \"lines.color\": \"white\",\n",
        "    \"patch.edgecolor\": \"white\",\n",
        "    \"text.color\": \"black\",\n",
        "    \"axes.facecolor\": \"white\",\n",
        "    \"axes.edgecolor\": \"lightgray\",\n",
        "    \"axes.labelcolor\": \"white\",\n",
        "    \"xtick.color\": \"white\",\n",
        "    \"ytick.color\": \"white\",\n",
        "    \"grid.color\": \"lightgray\",\n",
        "    \"figure.facecolor\": \"black\",\n",
        "    \"figure.edgecolor\": \"black\",\n",
        "    \"savefig.facecolor\": \"black\",\n",
        "    \"savefig.edgecolor\": \"black\"})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfOdJlbp39Fs",
        "colab_type": "text"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "This notebook builds on the notes in: [lecture-05-inference_complications.ipynb](https://colab.research.google.com/drive/15HffRKGBXlk_0u-IXvyza06y3Mt7_NTI).\n",
        "\n",
        "This notebook is **all** of problem set 5. The \"In-class foundations\" will count as 50 percent.\n",
        "\n",
        "## Part 1\n",
        "\n",
        "We will further explore the bias in: 'In the section \"Adjusting randomization proportions during experiment'.\n",
        "\n",
        "\n",
        "#### Weaknesses of the Bonferroni correction (40 points)\n",
        "\n",
        "We will return to the section \"Simulation to analyze power of procedures\". Our goal is to understand how dependence in the hypothesis tests reduces power when we use the Bonferroni correction.\n",
        "\n",
        "We need to create dependent hypothesis tests in our function `run_one_study`. You can replace your 80 independent normal random variables with 80 correlated random variables like this: `np.ones` creates an array entirely full of ones. We multiply it by a covariance between 0 and 1. `np.eye` creates a diagonal matrix with 1s on the diagonal and zeros elsewhere. We multiply by (1-covariance) to make the matrix `cov` always have 1s on the diagonal (i.e., all our variables will have variance=1). Substitute these into the data-generating process. Add a parameter `covariance` to your function so you can easily adjust the amount of covariance in your tests.\n",
        "\n",
        "If this isn't clear look at the `numpy` documentation.\n",
        "\n",
        "```\n",
        "cov = covariance*np.ones((number_of_hypotheses, number_of_hypotheses)) + (1-covariance)*np.eye(number_of_hypotheses)\n",
        "\n",
        "dataset = np.random.multivariate_normal(mean=effects, cov=cov, size=N_sample_size)\n",
        "```\n",
        "\n",
        "1. What does it mean for the hypothesis tests to be dependent? Why does this code make the hypothesis tests dependent?\n",
        "\n",
        "2. We are going to repeat \"Simulation to analyze power of procedures\" with different values for covariance. We are just looking at the Bonferroni correction right now. The notebook already gives you the results for covariance=0 (why?). We will also try very high covariance, 0.95. Simulate the high covariance DGP, and re-run the power and FWER calculations that are already in the notebook. Carefully compare these between covariance=0 and covariance=0.95. What do we mean when we say the Bonferroni correction is **very conservative** when there is dependence in the hypothesis tests?\n",
        "\n",
        "3. Try adjusting the  ùõº  parameter of your Bonferroni test. What power can you achieve while still controlling FWER < 0.05?\n",
        "\n",
        "4. In the Bonferroni correction power result in the notebook we calculated the power for the first 5 hypotheses using the simulated data and a special function from `statsmodels`. Reproduce these by manually coding it in your notebook. This should just be 1 or 2 lines of code. Show your code in the answer.\n",
        "\n",
        "#### Homework for Bonferroni correction (30 points)\n",
        "\n",
        "5. Repeat (2) but analyze the performance of the BH correction under high and low covariance. Is the BH as sensitive to covariance?\n",
        "\n",
        "6. Intuitively, why is the Bonferroni correction conservative when there is dependence?\n",
        "\n",
        "7. Describe an example experiment where hypothesis tests might be dependent?\n",
        "\n",
        "8. (Bonus +5) In the covariance matrix, why do we need to make sure the diagonal is always 1s, even when we change the covariance?\n",
        "\n",
        "9. (Bonus +5) In problem 6, sketch the proof using a mathematical (theory) argument.\n",
        "\n",
        "\n",
        "#### Peeking factors (20 points)\n",
        "\n",
        "10. Let's repeat the section 'Simulating the \"peeking\" experiments'. However we will peek less frequently. We started with $N=200$, but let's suppose we only peek once per day. We are a small website so we get just 50 visitors per day. You just need to modify `n_index = np.arange(4, df.shape[0])`. See the `np.arange` documentation on how to get only every k-th number in the range. How does decreasing the peeking frequency affect your false positive rate?\n",
        "\n",
        "11. Is \"peeking\" at the results literally a problem? That is, does just looking at your statistical results make them invalid? Explain.\n",
        "\n",
        "\n",
        "\n",
        "#### Homework for peeking (10 points)\n",
        "\n",
        "12. Repeat the simulation in the lecture notes notebook: 'Simulating the \"peeking\" experiments' but with $N=5000$. This takes longer so decrease to $B=500$. What is your overall false positive rate now? Try $N=10,000$ and $B=200$. What do you think happens to your false positive rate if you are willing to keep running each experiment forever?\n",
        "\n",
        "13. In a real-life situation, what are some reasons that you **should** peek at your experiment results?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeZbvj3CMLxL",
        "colab_type": "text"
      },
      "source": [
        "#Part 1\n",
        "##1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q22SbaLPRmG4",
        "colab_type": "text"
      },
      "source": [
        "This test became dependent as we put covariances in matrix, though before our correlations between metrics were equal to 0. So now they have dependence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BntRRAgR97C",
        "colab_type": "text"
      },
      "source": [
        "##2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBYKpV5ZSJ3p",
        "colab_type": "text"
      },
      "source": [
        "The notebook already gives you the results for covariance=0 as we normally distributed them. In other words, the scale is always = 1 and other elements of matrix = 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD6XwEL3MLc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_one_study(effect, covariance, false_nulls=[]):\n",
        "  N_sample_size = 100\n",
        "  number_of_hypotheses = 80\n",
        "\n",
        "  # If we want to plug in an actual effect for some of\n",
        "  # the measurements, we can pass a list of column numbers\n",
        "  # where we want to have `effect` rather than 0.\n",
        "  effects = np.zeros(number_of_hypotheses)\n",
        "  if false_nulls != []:\n",
        "    effects[false_nulls] = effect\n",
        "\n",
        "  cov = covariance*np.ones((number_of_hypotheses, number_of_hypotheses)) + (1-covariance)*np.eye(number_of_hypotheses)\n",
        "  # Make an array with N_sample_size rows and number_of_hypotheses columns.\n",
        "  # Each value is a draw from Normal(0, 1). We interpret this is as\n",
        "  # 100 units, each having 8 measurements.  We want to test whether\n",
        "  # the measurements are on average different from zero.\n",
        "  dataset = np.random.multivariate_normal(mean=effects, cov=cov, size=N_sample_size)\n",
        "\n",
        "  # This function does a 1-sample t-test on each column of the data.\n",
        "  # We are testing the hypothesis that the expectation of the column\n",
        "  # is 0.\n",
        "  test_results = stats.ttest_1samp(dataset, 0)\n",
        "  pvalues = pd.Series(test_results.pvalue)\n",
        "  return pvalues"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLHGC5M9S_GQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5401f383-ce6e-4714-d68e-88ead1056e5c"
      },
      "source": [
        "from scipy import stats\n",
        "B = 5000\n",
        "np.random.seed(94115)\n",
        "# Set the first 5 hypotheses to have an effect (loc!=0).\n",
        "# The remainder have no effect (loc=0).\n",
        "indices_has_effect = [0,1,2,3,4]\n",
        "pvalues_many_studies = [run_one_study(0.3, 0.95, indices_has_effect) for _ in progressbar(np.arange(B))]\n",
        "pvalues_uncorrected = pd.DataFrame(pvalues_many_studies)\n",
        "rejections_uncorrected = (pvalues_uncorrected < 0.05).cummax(axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (5000 of 5000) |####################| Elapsed Time: 0:00:17 Time:  0:00:17\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXJuWqriTXq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fdr(reject_corrected, indices_has_effect=indices_has_effect):\n",
        "  # Assumes that the first few indices can have true effects\n",
        "  # but the remaining columns will have true null hypotheses.\n",
        "  discoveries = reject_corrected.sum(axis=1)\n",
        "  false_discoveries = reject_corrected.loc[:, (indices_has_effect[-1] + 1):].sum(axis=1)\n",
        "  # False discovery quotient is defined as 0 when there are no rejections.\n",
        "  return (false_discoveries / discoveries).fillna(0).mean()\n",
        "\n",
        "def fwer(reject_corrected, indices_has_effect=indices_has_effect):\n",
        "  # Assumes that the first few indices can have true effects\n",
        "  # but the remaining columns will have true null hypotheses.\n",
        "  any_false_discoveries = reject_corrected.loc[:, (indices_has_effect[-1] + 1):].max(axis=1)\n",
        "  # False discovery quotient is defined as 0 when there are no rejections.\n",
        "  return any_false_discoveries.mean()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCpuYngbV-LV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statsmodels.sandbox.stats.multicomp import multipletests\n",
        "def get_multi_tester(result_type):\n",
        "  def multi_test_results(pvalues_row):\n",
        "    reject, pvals_corrected, _, _ = multipletests(pvalues_row, alpha=0.05, method=result_type)\n",
        "    return reject\n",
        "  return multi_test_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ww6l58NTXov",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a8e19b7e-47de-4b82-9015-bdcbedd18373"
      },
      "source": [
        "multi_test_results = get_multi_tester('bonferroni') \n",
        "reject_corrected = pvalues_uncorrected.apply(multi_test_results, axis=1, result_type='expand')\n",
        "\n",
        "# Power using bonferroni correction\n",
        "print(\"Power for the first 5 tests (Bonferroni):\")\n",
        "print(reject_corrected.loc[:, indices_has_effect].mean(axis=0))\n",
        "\n",
        "\n",
        "print(\"\\nFWER (Bonferroni) = \", fwer(reject_corrected))\n",
        "print(\"\\nFDR (Bonferroni) = \", fdr(reject_corrected))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Power for the first 5 tests (Bonferroni):\n",
            "0    0.3026\n",
            "1    0.3050\n",
            "2    0.3044\n",
            "3    0.3058\n",
            "4    0.3006\n",
            "dtype: float64\n",
            "\n",
            "FWER (Bonferroni) =  0.0028\n",
            "\n",
            "FDR (Bonferroni) =  0.0026481451148390816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3gVuOx9TXnp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a37be0cc-ecb9-46c7-c05f-9f872894790f"
      },
      "source": [
        "B = 5000\n",
        "np.random.seed(94115)\n",
        "# Set the first 5 hypotheses to have an effect (loc!=0).\n",
        "# The remainder have no effect (loc=0).\n",
        "indices_has_effect = [0,1,2,3,4]\n",
        "pvalues_many_studies = [run_one_study(0.3, 0, indices_has_effect) for _ in progressbar(np.arange(B))]\n",
        "pvalues_uncorrected = pd.DataFrame(pvalues_many_studies)\n",
        "rejections_uncorrected = (pvalues_uncorrected < 0.05).cummax(axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (5000 of 5000) |####################| Elapsed Time: 0:00:13 Time:  0:00:13\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHU-j7f0TXkK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4483dcd6-6e64-4603-96f0-5759714e8e1f"
      },
      "source": [
        "multi_test_results = get_multi_tester('bonferroni') \n",
        "reject_corrected = pvalues_uncorrected.apply(multi_test_results, axis=1, result_type='expand')\n",
        "\n",
        "# Power using bonferroni correction\n",
        "print(\"Power for the first 5 tests (Bonferroni):\")\n",
        "print(reject_corrected.loc[:, indices_has_effect].mean(axis=0))\n",
        "\n",
        "\n",
        "print(\"\\nFWER (Bonferroni) = \", fwer(reject_corrected))\n",
        "print(\"\\nFDR (Bonferroni) = \", fdr(reject_corrected))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Power for the first 5 tests (Bonferroni):\n",
            "0    0.3064\n",
            "1    0.2966\n",
            "2    0.3174\n",
            "3    0.3064\n",
            "4    0.3012\n",
            "dtype: float64\n",
            "\n",
            "FWER (Bonferroni) =  0.049\n",
            "\n",
            "FDR (Bonferroni) =  0.023536666666666647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpdiW0F8Xo9A",
        "colab_type": "text"
      },
      "source": [
        "the Bonferroni correction is very conservative when there is dependence in the hypothesis tests as it is so close to 0, as we have covariance = 0.95 but error is closer to 0, as compared to alpha. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmZsSKxhakig",
        "colab_type": "text"
      },
      "source": [
        "##3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEfj7AYPTXhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statsmodels.sandbox.stats.multicomp import multipletests\n",
        "def get_multi_tester(alpha, result_type):\n",
        "  def multi_test_results(pvalues_row):\n",
        "    reject, pvals_corrected, _, _ = multipletests(pvalues_row, alpha=alpha, method=result_type)\n",
        "    return reject\n",
        "  return multi_test_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUDG6SjtTXfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = 0.05"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CFUJIRtyewS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#B = 5000\n",
        "#np.random.seed(94115)\n",
        "# Set the first 5 hypotheses to have an effect (loc!=0).\n",
        "# The remainder have no effect (loc=0).\n",
        "#indices_has_effect = [0,1,2,3,4]\n",
        "#pvalues_many_studies = [run_one_study(0.3, indices_has_effect) for _ in progressbar(np.arange(B))]\n",
        "#pvalues_uncorrected = pd.DataFrame(pvalues_many_studies)\n",
        "#rejections_uncorrected = (pvalues_uncorrected < 0.05).cummax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4-mkg9ZTXcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c428141-540a-4afb-a808-0e9c94f0836b"
      },
      "source": [
        "B = 5000\n",
        "np.random.seed(94115)\n",
        "# Set the first 5 hypotheses to have an effect (loc!=0).\n",
        "# The remainder have no effect (loc=0).\n",
        "indices_has_effect = [0,1,2,3,4]\n",
        "pvalues_many_studies = [run_one_study(0.3, 0.95, indices_has_effect) for _ in progressbar(np.arange(B))]\n",
        "pvalues_uncorrected = pd.DataFrame(pvalues_many_studies)\n",
        "rejections_uncorrected = (pvalues_uncorrected < 0.05).cummax(axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (5000 of 5000) |####################| Elapsed Time: 0:00:17 Time:  0:00:17\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sptl8ftzTXac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do a manual Bonferroni correction on the p-values and calculate the FWER\n",
        "alpha = [0.05, 0.07, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.6, 0.7, 0.8]\n",
        "fwer_bonferroni = []\n",
        "for i in np.arange(0, 14):\n",
        "  fwer = (pvalues_uncorrected.iloc[:, 5:] < (alpha[i] / 80)).max(axis=1).mean()\n",
        "  fwer_bonferroni.append({'fwer': fwer, 'alpha': alpha[i]})\n",
        "  \n",
        "fwer_bonferroni = pd.DataFrame(fwer_bonferroni)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpLRneHXTXWp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "3836d442-16b0-444a-cc9d-cee235e765d6"
      },
      "source": [
        "fwer_bonferroni.plot(kind = 'scatter', x = 'alpha', y = 'fwer', color = 'green')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb9d73edb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmPme1zArn_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e121c7b4-a256-4746-a0b8-ff40be8822f1"
      },
      "source": [
        "reject_uncorrected = (pvalues_uncorrected < 0.05)\n",
        "print(reject_uncorrected.loc[:, :4].mean(axis=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0.8456\n",
            "1    0.8474\n",
            "2    0.8370\n",
            "3    0.8400\n",
            "4    0.8424\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDVGjP4cCND5",
        "colab_type": "text"
      },
      "source": [
        "####Second question of q. 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmgBswMoCMF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_multi_tester(result_type):\n",
        "  def multi_test_results(pvalues_row):\n",
        "    reject, pvals_corrected, _, _ = multipletests(pvalues_row, alpha=0.01, method=result_type)\n",
        "    return reject\n",
        "  return multi_test_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWUG2_JzDBGA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "74133a65-8a74-460c-86e5-90cc0c378528"
      },
      "source": [
        "multi_test_results = get_multi_tester('bonferroni') \n",
        "reject_corrected = pvalues_uncorrected.apply(multi_test_results, axis=1, result_type='expand')\n",
        "\n",
        "# Power using bonferroni correction\n",
        "print(\"Power for the first 5 tests (Bonferroni):\")\n",
        "print(reject_corrected.loc[:,:4].mean(axis=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Power for the first 5 tests (Bonferroni):\n",
            "0    0.1732\n",
            "1    0.1722\n",
            "2    0.1690\n",
            "3    0.1716\n",
            "4    0.1726\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZrQrxgq1RjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_multi_tester(result_type):\n",
        "  def multi_test_results(pvalues_row):\n",
        "    reject, pvals_corrected, _, _ = multipletests(pvalues_row, alpha=0.8, method=result_type)\n",
        "    return reject\n",
        "  return multi_test_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP35gKHr1Va1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d54fd6ff-d29c-4e8d-9352-b312a91382cc"
      },
      "source": [
        "multi_test_results = get_multi_tester('bonferroni') \n",
        "reject_corrected = pvalues_uncorrected.apply(multi_test_results, axis=1, result_type='expand')\n",
        "\n",
        "# Power using bonferroni correction\n",
        "print(\"Power for the first 5 tests (Bonferroni):\")\n",
        "print(reject_corrected.loc[:,:4].mean(axis=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Power for the first 5 tests (Bonferroni):\n",
            "0    0.6458\n",
            "1    0.6436\n",
            "2    0.6450\n",
            "3    0.6428\n",
            "4    0.6458\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nUfv-wkDq3f",
        "colab_type": "text"
      },
      "source": [
        "##4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW4l3_X8Dy2X",
        "colab_type": "text"
      },
      "source": [
        "In the Bonferroni correction power result in the notebook we calculated the power for the first 5 hypotheses using the simulated data and a special function from statsmodels. Reproduce these by manually coding it in your notebook. This should just be 1 or 2 lines of code. Show your code in the answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvHXzN4w8DiC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be759fb2-c99b-4e8f-cd8d-980f71ef5eed"
      },
      "source": [
        "np.random.seed(94115)\n",
        "B = 5000\n",
        "indices_has_effect = [0,1,2,3,4]\n",
        "# Simulate 5000 studies, each with N=100 and 80 hypotheses.\n",
        "# We set all nulls to be true.\n",
        "pvalues_many_studies = [run_one_study(0.3, 0.95, indices_has_effect) for _ in progressbar(np.arange(B))]\n",
        "pvalues_uncorrected = pd.DataFrame(pvalues_many_studies)\n",
        "rejections_uncorrected = (pvalues_uncorrected < 0.05).cummax(axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (5000 of 5000) |####################| Elapsed Time: 0:00:17 Time:  0:00:17\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke9yLpp0E5TC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "29af0cde-465c-46c8-b7a0-e12bd5247d2f"
      },
      "source": [
        "reject_uncorrected = (pvalues_uncorrected < 0.05)\n",
        "\n",
        "# Power using bonferroni correction\n",
        "print(\"Power for the first 5 tests (uncorrected):\")\n",
        "print(reject_uncorrected.loc[:, indices_has_effect].mean(axis=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Power for the first 5 tests (uncorrected):\n",
            "0    0.8456\n",
            "1    0.8474\n",
            "2    0.8370\n",
            "3    0.8400\n",
            "4    0.8424\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLYdLGTKEScT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "912648c7-fcb8-4c17-c62a-510ee62868ce"
      },
      "source": [
        "reject_uncorrected1 = (pvalues_uncorrected < 0.05).mean(axis = 0)\n",
        "reject_uncorrected1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0.8456\n",
              "1     0.8474\n",
              "2     0.8370\n",
              "3     0.8400\n",
              "4     0.8424\n",
              "5     0.0482\n",
              "6     0.0470\n",
              "7     0.0480\n",
              "8     0.0466\n",
              "9     0.0496\n",
              "10    0.0490\n",
              "11    0.0486\n",
              "12    0.0508\n",
              "13    0.0470\n",
              "14    0.0474\n",
              "15    0.0486\n",
              "16    0.0490\n",
              "17    0.0506\n",
              "18    0.0464\n",
              "19    0.0494\n",
              "20    0.0494\n",
              "21    0.0478\n",
              "22    0.0496\n",
              "23    0.0452\n",
              "24    0.0470\n",
              "25    0.0460\n",
              "26    0.0466\n",
              "27    0.0460\n",
              "28    0.0494\n",
              "29    0.0514\n",
              "       ...  \n",
              "50    0.0490\n",
              "51    0.0482\n",
              "52    0.0470\n",
              "53    0.0486\n",
              "54    0.0470\n",
              "55    0.0480\n",
              "56    0.0478\n",
              "57    0.0480\n",
              "58    0.0486\n",
              "59    0.0490\n",
              "60    0.0486\n",
              "61    0.0484\n",
              "62    0.0486\n",
              "63    0.0492\n",
              "64    0.0466\n",
              "65    0.0502\n",
              "66    0.0496\n",
              "67    0.0476\n",
              "68    0.0476\n",
              "69    0.0462\n",
              "70    0.0480\n",
              "71    0.0498\n",
              "72    0.0466\n",
              "73    0.0494\n",
              "74    0.0498\n",
              "75    0.0506\n",
              "76    0.0466\n",
              "77    0.0498\n",
              "78    0.0476\n",
              "79    0.0494\n",
              "Length: 80, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHN3fla3RXZr",
        "colab_type": "text"
      },
      "source": [
        "##5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-04tQbdR3un",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "1ad32260-167a-4ef5-af28-90abd7810084"
      },
      "source": [
        "B = 5000\n",
        "np.random.seed(94115)\n",
        "# Set the first 5 hypotheses to have an effect (loc!=0).\n",
        "# The remainder have no effect (loc=0).\n",
        "indices_has_effect = [0,1,2,3,4]\n",
        "pvalues_many_studies = [run_one_study(0.3, 0.95, indices_has_effect) for _ in progressbar(np.arange(B))]\n",
        "pvalues_uncorrected = pd.DataFrame(pvalues_many_studies)\n",
        "rejections_uncorrected = (pvalues_uncorrected < 0.05).cummax(axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 14% (747 of 5000) |###                  | Elapsed Time: 0:00:02 ETA:   0:00:14"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-276abfe27e39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# The remainder have no effect (loc=0).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mindices_has_effect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpvalues_many_studies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrun_one_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_has_effect\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogressbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpvalues_uncorrected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvalues_many_studies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrejections_uncorrected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpvalues_uncorrected\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcummax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-276abfe27e39>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# The remainder have no effect (loc=0).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mindices_has_effect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpvalues_many_studies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrun_one_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_has_effect\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogressbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpvalues_uncorrected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvalues_many_studies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrejections_uncorrected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpvalues_uncorrected\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcummax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-67def9bce7b0>\u001b[0m in \u001b[0;36mrun_one_study\u001b[0;34m(effect, covariance, false_nulls)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m# 100 units, each having 8 measurements.  We want to test whether\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m# the measurements are on average different from zero.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meffects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_sample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;31m# This function does a 1-sample t-test on each column of the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvaCFW17SBmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statsmodels.sandbox.stats.multicomp import multipletests\n",
        "def get_multi_tester(result_type):\n",
        "  def multi_test_results(pvalues_row):\n",
        "    reject, pvals_corrected, _, _ = multipletests(pvalues_row, alpha=0.05, method=result_type)\n",
        "    return reject\n",
        "  return multi_test_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9rIPKbLE6cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi_test_results = get_multi_tester('fdr_bh') \n",
        "reject_corrected = pvalues_uncorrected.apply(multi_test_results, axis=1, result_type='expand')\n",
        "\n",
        "# Power using BH correction\n",
        "print(\"Power for the first 5 tests (BH):\")\n",
        "print(reject_corrected.loc[:, indices_has_effect].mean(axis=0))\n",
        "\n",
        "#print(\"\\nFWER (BH) = \", fwer(reject_corrected))\n",
        "print(\"\\nFDR (BH) = \", fdr(reject_corrected))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IzNM_--Sj3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "B = 5000\n",
        "np.random.seed(94115)\n",
        "# Set the first 5 hypotheses to have an effect (loc!=0).\n",
        "# The remainder have no effect (loc=0).\n",
        "indices_has_effect = [0,1,2,3,4]\n",
        "pvalues_many_studies = [run_one_study(0.3, 0, indices_has_effect) for _ in progressbar(np.arange(B))]\n",
        "pvalues_uncorrected = pd.DataFrame(pvalues_many_studies)\n",
        "rejections_uncorrected = (pvalues_uncorrected < 0.05).cummax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFfqww3oE6Wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi_test_results = get_multi_tester('fdr_bh') \n",
        "reject_corrected = pvalues_uncorrected.apply(multi_test_results, axis=1, result_type='expand')\n",
        "\n",
        "# Power using BH correction\n",
        "print(\"Power for the first 5 tests (BH):\")\n",
        "print(reject_corrected.loc[:, indices_has_effect].mean(axis=0))\n",
        "\n",
        "#print(\"\\nFWER (BH) = \", fwer(reject_corrected))\n",
        "print(\"\\nFDR (BH) = \", fdr(reject_corrected))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H8GO2kdStlN",
        "colab_type": "text"
      },
      "source": [
        "##6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5bLXExsYvvZ",
        "colab_type": "text"
      },
      "source": [
        "Answer: the Bonfferoni method is more conservative when the events of rejecting hypothesises are dependent. The reason for it is that their covariance is not zero. In other words, the probability of (we reject the first hypothesis and reject the second hypothesis) is very small. Obtaining both of these events are more difficult than obtainng them if they are independent as it means that we have to reject both of them to reach our goal. When they are independent, we need just to occur one event out of all of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrv2G39bd8X7",
        "colab_type": "text"
      },
      "source": [
        "##7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MQFUho_d-nv",
        "colab_type": "text"
      },
      "source": [
        "Example: the treatment is doing masters degree program. There are different effects. First, people will obtain more knowledge. Second, these students will be more likely to get job in future. This two effects could be considered as hypothesises tests. Hypothesis one: Necessary knowledge = 0. Hypothesis two: No getting job. Clearly, they might me dependent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SanQG-TOfc57",
        "colab_type": "text"
      },
      "source": [
        "##8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9gmlkamgGia",
        "colab_type": "text"
      },
      "source": [
        "Answer: in covariance matrix the main diagonal is variances of same variables. It will be always equal to 1 as if variable X changes to some value the same X will always change with probability 1 to the value as they are the same variables. Its covariance of variable to itself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSNyFTAHg1Jn",
        "colab_type": "text"
      },
      "source": [
        "##9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVxC4pN_g8sI",
        "colab_type": "text"
      },
      "source": [
        "P(A or B) = P(A) + P(B) - P(A and B);\n",
        "If events A and B are independent => the interaction of these two variables = 0;\n",
        "P(A(independent) or B(independent)) = P(A(ind)+B(ind));\n",
        "While P(A(dep) + B(dep)) = P(A(dep)) + P(B(dep)) - P(A(dep) and B(dep));\n",
        "As we know from axiom that P(any event) =>0; \n",
        "And in our case (as I explained) P(A(dep) and B(dep)) > 0 as they have interaction;\n",
        "P(A(independent) or B(independent)) >= P(A(dep) + B(dep));\n",
        "Consequently, when events are dependent, the probability of occuring any of them will be much less (as we have substraction in our formula) than in independent case.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ_665p6FLNS",
        "colab_type": "text"
      },
      "source": [
        "#Part 2\n",
        "##10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZuG7FyFSeyE",
        "colab_type": "text"
      },
      "source": [
        "Let's repeat the section 'Simulating the \"peeking\" experiments'. However we will peek less frequently. We started with  ùëÅ=200 , but let's suppose we only peek once per day. We are a small website so we get just 50 visitors per day. You just need to modify n_index = np.arange(4, df.shape[0]). See the np.arange documentation on how to get only every k-th number in the range. How does decreasing the peeking frequency affect your false positive rate?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atPo_iamI_nU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_one_dataset(N=200, ATE = 0):\n",
        "  \"\"\"Make data from one experiment with a specified ATE.\n",
        "  \n",
        "  \n",
        "  To speed things up we split the sample in two and put\n",
        "  the control group in the first column and the treatment\n",
        "  group in the second column.\n",
        "  \"\"\"\n",
        "\n",
        "  # potential outcomes are normally distributed\n",
        "  Y_control = np.random.normal(loc=0, size=(int(N / 2), 1))\n",
        "  Y_treatment = np.random.normal(loc=ATE, size=(int(N / 2), 1))\n",
        "\n",
        "  # Stack the groups side by side in a (100, 2) array.\n",
        "  return np.hstack((Y_control, Y_treatment))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUMix2epJCTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_pvalue_sequence(N):\n",
        "  # Make data from one experiment\n",
        "  df = gen_one_dataset(N=N)\n",
        "  # Do the ttest cumulatively through the array:\n",
        "  # the first 5 rows, the first 6 rows, the first 7, and so on.\n",
        "  # This assumes we get treatment and control observations in pairs,\n",
        "  # which may not be realistic but does not matter for our demonstration.\n",
        "  n_index = np.arange(4, df.shape[0], 25)\n",
        "  # Note that we index the dataframe starting at 1 for correct plotting\n",
        "  running_pvalues = pd.Series(np.array([get_pvalue_analysis(df[0:n, :]) for n in n_index]), index=2 * (n_index + 1))\n",
        "  return running_pvalues\n",
        "\n",
        "def get_pvalue_analysis(df):    \n",
        "    \"\"\"Do a two-sample t-test to get the p-value.\"\"\"\n",
        "    results = stats.ttest_ind(df[:, 0], df[:, 1])\n",
        "    return results.pvalue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6D11JRuStIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(94115)\n",
        "B = 1000 # simulate 1000 experiments\n",
        "N = 200\n",
        "sims_peeking_experiments = pd.DataFrame([gen_pvalue_sequence(N=N) for _ in progressbar(np.arange(B))]).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sdfTIxFE6Pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For each experiment, find the first test where the p-value was below 0.05.\n",
        "first_significant_row = sims_peeking_experiments[sims_peeking_experiments < 0.05].idxmin(axis=0)\n",
        "\n",
        "# Check if our test was ever \"significant\" before we reached the end of the experiment.\n",
        "is_significant_early = (first_significant_row < N).fillna(False)  # Note that we switched to indexing starting at 1\n",
        "\n",
        "# Check if the test was \"significant\" at the end of the experiment,\n",
        "# i.e., the last row, when we have reached the pre-determined sample size\n",
        "is_significant_at_full_sample = (sims_peeking_experiments.tail(1) < 0.05)\n",
        "\n",
        "results_of_experiments = pd.DataFrame({\n",
        "    'is_significant_at_full_sample': is_significant_at_full_sample.T.values.flatten(),\n",
        "    'is_significant_early': is_significant_early.values\n",
        "\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izRwf7aekQ0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_of_experiments.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NExeERekl7cP",
        "colab_type": "text"
      },
      "source": [
        "Answer: error rate becomes higher than 0.05. It means that by decreasing the peeking frequency, false positive rate becomes higher than it was setted before. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlJ614knlUoY",
        "colab_type": "text"
      },
      "source": [
        "##11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXajMzA8Lm5E",
        "colab_type": "text"
      },
      "source": [
        "Is \"peeking\" at the results literally a problem? That is, does just looking at your statistical results make them invalid? Explain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hju4-UYTLhCq",
        "colab_type": "text"
      },
      "source": [
        "Answer: Yes, it is a problem. We know that under the null hypothesis, a test with level  ùõº=0.05  will reject in 5 percent of repeated samples. \n",
        "\"Peeking\" tends to create a discrepancy between p-value, which we calculated, and the true p-value, which we set. By looking our statistical results, we conclude that our calculated error is higher than our nominal value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q5S3ycU-by0",
        "colab_type": "text"
      },
      "source": [
        "##12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiUa5FJo-ioN",
        "colab_type": "text"
      },
      "source": [
        "Repeat the simulation in the lecture notes notebook: 'Simulating the \"peeking\" experiments' but with  ùëÅ=5000 . This takes longer so decrease to  ùêµ=500 . What is your overall false positive rate now? Try  ùëÅ=10,000  and  ùêµ=200 . What do you think happens to your false positive rate if you are willing to keep running each experiment forever?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KqEHos3kd3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(94115)\n",
        "B = 500 # simulate 500 experiments\n",
        "N = 5000\n",
        "sims_peeking_experiments = pd.DataFrame([gen_pvalue_sequence(N=N) for _ in progressbar(np.arange(B))]).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yObmSsTykd1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For each experiment, find the first test where the p-value was below 0.05.\n",
        "first_significant_row = sims_peeking_experiments[sims_peeking_experiments < 0.05].idxmin(axis=0)\n",
        "\n",
        "# Check if our test was ever \"significant\" before we reached the end of the experiment.\n",
        "is_significant_early = (first_significant_row < N).fillna(False)  # Note that we switched to indexing starting at 1\n",
        "\n",
        "# Check if the test was \"significant\" at the end of the experiment,\n",
        "# i.e., the last row, when we have reached the pre-determined sample size\n",
        "is_significant_at_full_sample = (sims_peeking_experiments.tail(1) < 0.05)\n",
        "\n",
        "results_of_experiments = pd.DataFrame({\n",
        "    'is_significant_at_full_sample': is_significant_at_full_sample.T.values.flatten(),\n",
        "    'is_significant_early': is_significant_early.values\n",
        "\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5oUZvftkdub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print errors rates from experiment simulations\n",
        "results_of_experiments.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkF5sXp8kdsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(94115)\n",
        "B = 200 # simulate 200 experiments\n",
        "N = 10000\n",
        "sims_peeking_experiments = pd.DataFrame([gen_pvalue_sequence(N=N) for _ in progressbar(np.arange(B))]).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAm_KjoJkdoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For each experiment, find the first test where the p-value was below 0.05.\n",
        "first_significant_row = sims_peeking_experiments[sims_peeking_experiments < 0.05].idxmin(axis=0)\n",
        "\n",
        "# Check if our test was ever \"significant\" before we reached the end of the experiment.\n",
        "is_significant_early = (first_significant_row < N).fillna(False)  # Note that we switched to indexing starting at 1\n",
        "\n",
        "# Check if the test was \"significant\" at the end of the experiment,\n",
        "# i.e., the last row, when we have reached the pre-determined sample size\n",
        "is_significant_at_full_sample = (sims_peeking_experiments.tail(1) < 0.05)\n",
        "\n",
        "results_of_experiments2 = pd.DataFrame({\n",
        "    'is_significant_at_full_sample': is_significant_at_full_sample.T.values.flatten(),\n",
        "    'is_significant_early': is_significant_early.values\n",
        "\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBhJGPe5kdmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print errors rates from experiment simulations\n",
        "results_of_experiments2.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeixhopUkdfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"false positive rate in (N=5000, B=500) = \", results_of_experiments.mean()[0])\n",
        "print(\"false positive rate in (N=10000, B=200) = \", results_of_experiments2.mean()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZEbIAGVIR5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(94115)\n",
        "B = 500 # simulate 500 experiments\n",
        "N = 10000\n",
        "sims_peeking_experiments = pd.DataFrame([gen_pvalue_sequence(N=N) for _ in progressbar(np.arange(B))]).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNWsj4ZQIXs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For each experiment, find the first test where the p-value was below 0.05.\n",
        "first_significant_row = sims_peeking_experiments[sims_peeking_experiments < 0.05].idxmin(axis=0)\n",
        "\n",
        "# Check if our test was ever \"significant\" before we reached the end of the experiment.\n",
        "is_significant_early = (first_significant_row < N).fillna(False)  # Note that we switched to indexing starting at 1\n",
        "\n",
        "# Check if the test was \"significant\" at the end of the experiment,\n",
        "# i.e., the last row, when we have reached the pre-determined sample size\n",
        "is_significant_at_full_sample = (sims_peeking_experiments.tail(1) < 0.05)\n",
        "\n",
        "results_of_experiments2 = pd.DataFrame({\n",
        "    'is_significant_at_full_sample': is_significant_at_full_sample.T.values.flatten(),\n",
        "    'is_significant_early': is_significant_early.values\n",
        "\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bezApqgiIdqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print errors rates from experiment simulations\n",
        "results_of_experiments2.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcXbdukoGYsU",
        "colab_type": "text"
      },
      "source": [
        "Answer: \n",
        "If I keep running aech experiment N times, where N strives to +infinity, it can be clearly seen that the false positive rate will grow rapidly. I think that the reason for it is the huge number of experiments leads to the increase of frequency of peeking. In other words, the false positive of each test compounds increasing the overall probability.\n",
        "As we can see above I took also the same number of experiments( B = 500) and rendered data with 5000 and 10000 visitors checked per day, and the number of visitors is directly linked with increasing false positive rate. (0.054 and 0.068 respectively)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6kJu3joJxIb",
        "colab_type": "text"
      },
      "source": [
        "##13"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SHw7N6OJ23_",
        "colab_type": "text"
      },
      "source": [
        "In a real-life situation, what are some reasons that you should peek at your experiment results?\n",
        "The main benefit of using \"peeking\" is when we have some initial false positive rate (for example, 0.05) and want to obtain in a certain pick false positive rate (example: 0.001) to reach some significance. The main point is the fact that if you are focuded on getting 5% of actual significant result, you could reduce the percentage of reported significance by increasing the number of experiments. "
      ]
    }
  ]
}