{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Case Study 4.1 - Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">Note: If you close this notebook at any time, you will have to run all cells again upon re-opening it.</h1>\n",
    "\n",
    "<h1 style=\"color:red;\">Note: You may get different numerical results running the notebook different times. This is to be expected, you can just report whatever results you get.</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADVANCED PYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is an advanced version, we don't include a lot of code here. If you get stuck on a particular part, feel free to also use the beginner version in `beginnner_python.ipynb` to help you out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR NAME              = Armen Khachatrian\n",
    "# YOUR MITX PRO USERNAME = armen-khachatrian\n",
    "# YOUR MITX PRO E-MAIL   = aa.khachatryan97@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run these cells to install all the packages you need to complete the remainder of the case study. This may take a few minutes, so please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise==0.1\n",
      "  Using cached https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
      "Collecting scikit-surprise\n",
      "  Using cached https://files.pythonhosted.org/packages/f5/da/b5700d96495fb4f092be497f02492768a3d96a3f4fa2ae7dea46d4081cfa/scikit-surprise-1.1.0.tar.gz\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/a.khachatryan/anaconda3/lib/python3.6/site-packages (from scikit-surprise->surprise==0.1) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /Users/a.khachatryan/anaconda3/lib/python3.6/site-packages (from scikit-surprise->surprise==0.1) (1.16.3)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/a.khachatryan/anaconda3/lib/python3.6/site-packages (from scikit-surprise->surprise==0.1) (1.2.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/a.khachatryan/anaconda3/lib/python3.6/site-packages (from scikit-surprise->surprise==0.1) (1.12.0)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /Users/a.khachatryan/anaconda3/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/q7/1xn5m1555ws7kn30v5f1yvyw0000gn/T/pip-install-69frhtmb/scikit-surprise/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/q7/1xn5m1555ws7kn30v5f1yvyw0000gn/T/pip-install-69frhtmb/scikit-surprise/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /private/var/folders/q7/1xn5m1555ws7kn30v5f1yvyw0000gn/T/pip-wheel-xwt92ewj --python-tag cp36\n",
      "       cwd: /private/var/folders/q7/1xn5m1555ws7kn30v5f1yvyw0000gn/T/pip-install-69frhtmb/scikit-surprise/\n",
      "  Complete output (53 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.macosx-10.7-x86_64-3.6\n",
      "  creating build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "  copying surprise/builtin_datasets.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "  copying surprise/__init__.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "  copying surprise/dump.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "  copying surprise/dataset.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "  copying surprise/reader.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "  copying surprise/utils.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "  copying surprise/trainset.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "  copying surprise/accuracy.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "  copying surprise/__main__.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "  creating build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "  copying surprise/prediction_algorithms/algo_base.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "  copying surprise/prediction_algorithms/knns.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "  copying surprise/prediction_algorithms/predictions.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "  copying surprise/prediction_algorithms/__init__.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "  copying surprise/prediction_algorithms/random_pred.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "  copying surprise/prediction_algorithms/baseline_only.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "  creating build/lib.macosx-10.7-x86_64-3.6/surprise/model_selection\n",
      "  copying surprise/model_selection/__init__.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/model_selection\n",
      "  copying surprise/model_selection/split.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/model_selection\n",
      "  copying surprise/model_selection/search.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/model_selection\n",
      "  copying surprise/model_selection/validation.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/model_selection\n",
      "  running egg_info\n",
      "  writing scikit_surprise.egg-info/PKG-INFO\n",
      "  writing dependency_links to scikit_surprise.egg-info/dependency_links.txt\n",
      "  writing entry points to scikit_surprise.egg-info/entry_points.txt\n",
      "  writing requirements to scikit_surprise.egg-info/requires.txt\n",
      "  writing top-level names to scikit_surprise.egg-info/top_level.txt\n",
      "  reading manifest file 'scikit_surprise.egg-info/SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  writing manifest file 'scikit_surprise.egg-info/SOURCES.txt'\n",
      "  copying surprise/similarities.c -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "  copying surprise/similarities.pyx -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "  copying surprise/prediction_algorithms/co_clustering.c -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "  copying surprise/prediction_algorithms/co_clustering.pyx -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "  copying surprise/prediction_algorithms/matrix_factorization.c -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "  copying surprise/prediction_algorithms/matrix_factorization.pyx -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "  copying surprise/prediction_algorithms/optimize_baselines.c -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "  copying surprise/prediction_algorithms/optimize_baselines.pyx -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "  copying surprise/prediction_algorithms/slope_one.c -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "  copying surprise/prediction_algorithms/slope_one.pyx -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "  running build_ext\n",
      "  building 'surprise.similarities' extension\n",
      "  creating build/temp.macosx-10.7-x86_64-3.6\n",
      "  creating build/temp.macosx-10.7-x86_64-3.6/surprise\n",
      "  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/a.khachatryan/anaconda3/include -arch x86_64 -I/Users/a.khachatryan/anaconda3/include -arch x86_64 -I/Users/a.khachatryan/anaconda3/lib/python3.6/site-packages/numpy/core/include -I/Users/a.khachatryan/anaconda3/include/python3.6m -c surprise/similarities.c -o build/temp.macosx-10.7-x86_64-3.6/surprise/similarities.o\n",
      "  xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun\n",
      "  error: command 'gcc' failed with exit status 1\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for scikit-surprise\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for scikit-surprise\n",
      "Failed to build scikit-surprise\n",
      "Installing collected packages: scikit-surprise, surprise\n",
      "    Running setup.py install for scikit-surprise ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Users/a.khachatryan/anaconda3/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/q7/1xn5m1555ws7kn30v5f1yvyw0000gn/T/pip-install-69frhtmb/scikit-surprise/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/q7/1xn5m1555ws7kn30v5f1yvyw0000gn/T/pip-install-69frhtmb/scikit-surprise/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/q7/1xn5m1555ws7kn30v5f1yvyw0000gn/T/pip-record-oaf51th1/install-record.txt --single-version-externally-managed --compile\n",
      "         cwd: /private/var/folders/q7/1xn5m1555ws7kn30v5f1yvyw0000gn/T/pip-install-69frhtmb/scikit-surprise/\n",
      "    Complete output (53 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.macosx-10.7-x86_64-3.6\n",
      "    creating build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "    copying surprise/builtin_datasets.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "    copying surprise/__init__.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "    copying surprise/dump.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "    copying surprise/dataset.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "    copying surprise/reader.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "    copying surprise/utils.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "    copying surprise/trainset.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "    copying surprise/accuracy.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "    copying surprise/__main__.py -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "    creating build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "    copying surprise/prediction_algorithms/algo_base.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "    copying surprise/prediction_algorithms/knns.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "    copying surprise/prediction_algorithms/predictions.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "    copying surprise/prediction_algorithms/__init__.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "    copying surprise/prediction_algorithms/random_pred.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "    copying surprise/prediction_algorithms/baseline_only.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "    creating build/lib.macosx-10.7-x86_64-3.6/surprise/model_selection\n",
      "    copying surprise/model_selection/__init__.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/model_selection\n",
      "    copying surprise/model_selection/split.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/model_selection\n",
      "    copying surprise/model_selection/search.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/model_selection\n",
      "    copying surprise/model_selection/validation.py -> build/lib.macosx-10.7-x86_64-3.6/surprise/model_selection\n",
      "    running egg_info\n",
      "    writing scikit_surprise.egg-info/PKG-INFO\n",
      "    writing dependency_links to scikit_surprise.egg-info/dependency_links.txt\n",
      "    writing entry points to scikit_surprise.egg-info/entry_points.txt\n",
      "    writing requirements to scikit_surprise.egg-info/requires.txt\n",
      "    writing top-level names to scikit_surprise.egg-info/top_level.txt\n",
      "    reading manifest file 'scikit_surprise.egg-info/SOURCES.txt'\n",
      "    reading manifest template 'MANIFEST.in'\n",
      "    writing manifest file 'scikit_surprise.egg-info/SOURCES.txt'\n",
      "    copying surprise/similarities.c -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "    copying surprise/similarities.pyx -> build/lib.macosx-10.7-x86_64-3.6/surprise\n",
      "    copying surprise/prediction_algorithms/co_clustering.c -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "    copying surprise/prediction_algorithms/co_clustering.pyx -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "    copying surprise/prediction_algorithms/matrix_factorization.c -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "    copying surprise/prediction_algorithms/matrix_factorization.pyx -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "    copying surprise/prediction_algorithms/optimize_baselines.c -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "    copying surprise/prediction_algorithms/optimize_baselines.pyx -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "    copying surprise/prediction_algorithms/slope_one.c -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "    copying surprise/prediction_algorithms/slope_one.pyx -> build/lib.macosx-10.7-x86_64-3.6/surprise/prediction_algorithms\n",
      "    running build_ext\n",
      "    building 'surprise.similarities' extension\n",
      "    creating build/temp.macosx-10.7-x86_64-3.6\n",
      "    creating build/temp.macosx-10.7-x86_64-3.6/surprise\n",
      "    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/a.khachatryan/anaconda3/include -arch x86_64 -I/Users/a.khachatryan/anaconda3/include -arch x86_64 -I/Users/a.khachatryan/anaconda3/lib/python3.6/site-packages/numpy/core/include -I/Users/a.khachatryan/anaconda3/include/python3.6m -c surprise/similarities.c -o build/temp.macosx-10.7-x86_64-3.6/surprise/similarities.o\n",
      "    xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun\n",
      "    error: command 'gcc' failed with exit status 1\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /Users/a.khachatryan/anaconda3/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/q7/1xn5m1555ws7kn30v5f1yvyw0000gn/T/pip-install-69frhtmb/scikit-surprise/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/q7/1xn5m1555ws7kn30v5f1yvyw0000gn/T/pip-install-69frhtmb/scikit-surprise/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/q7/1xn5m1555ws7kn30v5f1yvyw0000gn/T/pip-record-oaf51th1/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install surprise==0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you must press **Kernel > Restart.** This allows the installation to take effect. Once you see the blue **Connected/Kernel ready** button in the top right, you are good to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0e8b7891fbcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormalPredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaselineOnly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKNNBasic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNMF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "from surprise import Dataset, SVD, NormalPredictor, BaselineOnly, KNNBasic, NMF\n",
    "from surprise.model_selection import cross_validate, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [`**Dataset.load_builtin**`](http://surprise.readthedocs.io/en/stable/dataset.html#surprise.dataset.Dataset.load_builtin) function to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dde8d35619c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ml-100k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to get a sense of what the data looks like. Please create a histogram of all the ratings we have in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6f9a29d358>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Get the ratings file from the data object\n",
    "# This is just a filename that has all the data stored in it\n",
    "ratings_file = data.ratings_file\n",
    "\n",
    "\n",
    "# 2. Load that table using pandas, a commmon python data loading tool\n",
    "# We set the column names manually here\n",
    "col_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "raw_data = pd.read_table(ratings_file, names=col_names)\n",
    "\n",
    "# 3. Get the rating column\n",
    "ratings = raw_data.rating\n",
    "\n",
    "# 4. Generate a bar plot/histogram of that data\n",
    "ratings.value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations:  100000\n",
      "Mean =  3.52986\n",
      "Median =  4.0\n",
      "Mode =  4\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "mean = statistics.mean(ratings)\n",
    "median = statistics.median(ratings)\n",
    "mode = statistics.mode(ratings)\n",
    "print(\"Number of observations: \", len(ratings))\n",
    "print(\"Mean = \", mean)\n",
    "print(\"Median = \", median)\n",
    "print(\"Mode = \", mode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">QUESTION 1: DATA ANALYSIS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Describe the dataset. How many ratings are in the dataset? How would you describe the distribution of ratings? Is there anything else we should observe? Make sure the histogram is visible in the notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How many ratings are in the dataset?\n",
    "100000\n",
    "#### 2. How would you describe the distribution of ratings?\n",
    "\n",
    "2.1. **Shape**: approximately symmetric distribution\n",
    "\n",
    "2.2. **Center**: \n",
    "            \n",
    "            Mean = 3.52986\n",
    "            \n",
    "            Median = 4.0\n",
    "            \n",
    "            Mode = 4\n",
    "            \n",
    "2.3. **Spread**: range = 4\n",
    "\n",
    "2.4. **Outliers** = No apparent outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using NormalPredictor() class\n",
    "model_random = NormalPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.5233  1.5138  1.5141  1.5257  1.5241  1.5202  0.0052  \n",
      "Fit time          0.53    0.73    0.57    0.70    0.70    0.64    0.08    \n",
      "Test time         0.95    0.60    0.85    0.62    0.80    0.76    0.13    \n"
     ]
    }
   ],
   "source": [
    "# Train on data using cross-validation with k=5 folds, measuring the RMSE\n",
    "# See the cross_validate function that we have imported above\n",
    "# http://surprise.readthedocs.io/en/stable/model_selection.html#surprise.model_selection.validation.cross_validate\n",
    "model_random_results = cross_validate(model_random, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: User-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using KNNBasic() class\n",
    "# See the sim_options parameter to determine the user/item similarity calculation of the model\n",
    "# http://surprise.readthedocs.io/en/stable/prediction_algorithms.html#similarity-measures-configuration\n",
    "sim_options = {'user_based': True}\n",
    "model_user = KNNBasic(sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9856  0.9746  0.9751  0.9773  0.9830  0.9791  0.0044  \n",
      "Fit time          1.23    1.35    1.14    1.01    1.15    1.18    0.11    \n",
      "Test time         15.25   16.59   16.29   15.18   15.55   15.77   0.57    \n"
     ]
    }
   ],
   "source": [
    "# Train using same cross validation code as above\n",
    "model_user_results = cross_validate(model_user, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Item-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using KNNBasic() class\n",
    "# Make sure you change the sim_options parameter from above\n",
    "sim_options = {'user_based': False}\n",
    "model_item = KNNBasic(sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9729  0.9710  0.9800  0.9758  0.9685  0.9736  0.0040  \n",
      "Fit time          8.36    12.16   1.96    1.93    2.21    5.32    4.21    \n",
      "Test time         19.75   19.88   19.86   19.43   19.20   19.62   0.27    \n"
     ]
    }
   ],
   "source": [
    "# Train using same cross validation code as above\n",
    "model_item_results = cross_validate(model_item, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">QUESTION 2: COLLABORATIVE FILTERING MODELS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the results from the user-user and item-item models. How do they compare to each other? How do they compare to our original \"random\" model? Can you provide any intuition as to why the results came out the way they did?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do they compare to each other?\n",
    "\n",
    "Mean RMSE user-user: 0.9788\n",
    "\n",
    "Mean RMSE item-item: 0.9743\n",
    "\n",
    "**Note**: item-item collaborative model has less average RMSE, as opposed to user-user. But the difference is in thousandths, and their average RMSE is approximately the same. Although test time of item-item collaborative model is comparably larger than user-user model (17.01 and 11.44, respectively)\n",
    "\n",
    "#### 2. How do they compare to our original \"random\" model?\n",
    "\n",
    "The average RMSE of random model is poorer than the user-user and item-item collaborative models (Mean RMSE random: 1.5167). But the time spent on testing data is much less. (Average test time = 0.58)\n",
    "            \n",
    "#### 3. Can you provide any intuition as to why the results came out the way they did?\n",
    "The mean of RMSE of random model is higher because this algorithm uses no information about the data. That is why collaborative filtering models have better values of average RMSE as these models are personalized. We take into account individuals' features  and movies' details. The average RMSE user-user is less than average RMSE of item-item due to the certain reason. Collaborative filtering of users requires to compute inner products between rows (each user). The main constraint is that each user has rated a very small fraction of movies, and the raws are empty, in general. Therefore, it makes sense to focus on movies, which are most frequently rated (it means that they are popular). So we have a lot of ratings for these movies, and we can compute inner products between columns rather than rows. And in case of item-item model (columns), we have more collisions, as opposed to user-user collaborative model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using SVD() class\n",
    "model_mf = SVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9396  0.9343  0.9282  0.9510  0.9305  0.9367  0.0081  \n",
      "Fit time          25.27   45.18   47.84   42.22   29.07   37.91   9.03    \n",
      "Test time         4.49    4.72    3.15    1.52    1.26    3.03    1.45    \n"
     ]
    }
   ],
   "source": [
    "# Train using same cross validation code as above\n",
    "model_mf_results = cross_validate(model_mf, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">QUESTION 3: MATRIX FACTORIZATION MODEL</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The matrix factorization model is different from the collaborative filtering models. Briefly describe this difference. Also, compare the RMSE again. Does it improve? Can you offer any reasoning as to why that might be?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Difference between matrix factorization and collaborative filtering models:\n",
    "Collaborative filtering models predict unknown user preferences based on existed rates and/or other users' behaviours. The main feature of these methods is the fact that users, who have similarly rated movies, have a tendency to similarly rate other movies.\n",
    "Matrix factorization could reveal implicit factors related to user-item connection. The goal of matrix factorization is matrix expansion in product of two other matrices. The initial matrix is user-item. Missing ratings could be predicted by calculating squared error and gradient of it, and getting values of two matrices. So MF is the method of CF.  \n",
    "#### 2. RMSE comparison:\n",
    "The mean RMSE of CF is poorer than the average RMSE of MF. So it improved\n",
    "#### 3. Can you offer any reasoning as to why that might be?\n",
    "I think the difference is due to the fact that matrix factorization could find implicit patterns, as compared to CF models, which make predictions with clear correlations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall @ `k`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to compute the precision and recall for 2 values of `k`: 5 and 10. We have provided some code here to help you do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a function that takes in some predictions, a value of `k` and a threshold parameter. This code is adapted from [here](http://surprise.readthedocs.io/en/stable/FAQ.html?highlight=precision#how-to-compute-precision-k-and-recall-k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = dict()\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        current = user_est_true.get(uid, list())\n",
    "        current.append((est, true_r))\n",
    "        user_est_true[uid] = current\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the precision and recall at `k` = 5 and 10 for each of our 4 models. We use 5-fold cross validation again to average the results across the entire dataseat.\n",
    "\n",
    "Please note that this will take some time to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">QUESTION 4: PRECISION/RECALL</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the precision and recall, for each of the 4 models, at `k` = 5 and 10. This is 2 x 2 x 4 = 16 numerical values. Do you note anything interesting about these values? Anything differerent from the RMSE values you computed above?**\n",
    "\n",
    "Some code is required for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> k=5, model=NormalPredictor\n",
      ">>> precision: 0.588\n",
      ">>> reccall  : 0.342\n",
      "\n",
      "\n",
      ">>> k=5, model=KNNBasic\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      ">>> precision: 0.764\n",
      ">>> reccall  : 0.455\n",
      "\n",
      "\n",
      ">>> k=5, model=KNNBasic\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      ">>> precision: 0.816\n",
      ">>> reccall  : 0.39\n",
      "\n",
      "\n",
      ">>> k=5, model=SVD\n",
      ">>> precision: 0.78\n",
      ">>> reccall  : 0.435\n",
      "\n",
      "\n",
      ">>> k=10, model=NormalPredictor\n",
      ">>> precision: 0.59\n",
      ">>> reccall  : 0.431\n",
      "\n",
      "\n",
      ">>> k=10, model=KNNBasic\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      ">>> precision: 0.736\n",
      ">>> reccall  : 0.591\n",
      "\n",
      "\n",
      ">>> k=10, model=KNNBasic\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      ">>> precision: 0.789\n",
      ">>> reccall  : 0.536\n",
      "\n",
      "\n",
      ">>> k=10, model=SVD\n",
      ">>> precision: 0.76\n",
      ">>> reccall  : 0.562\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the function above to compute the 16 numerical values requested above\n",
    "# See the test() function to get the predictions input to the function\n",
    "# http://surprise.readthedocs.io/en/stable/algobase.html#surprise.prediction_algorithms.algo_base.AlgoBase.test\n",
    "# Make list of k values\n",
    "K = [5, 10]\n",
    "\n",
    "# Make list of models\n",
    "models = [model_random, model_user, model_item, model_mf]\n",
    "\n",
    "# Create k-fold cross validation object\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for k in K:\n",
    "    for model in models:\n",
    "        print(f'>>> k={k}, model={model.__class__.__name__}')\n",
    "        # Run folder and take average\n",
    "        p = []\n",
    "        r = []\n",
    "        for trainset, testset in kf.split(data):\n",
    "            model.fit(trainset)\n",
    "            predictions = model.test(testset, verbose=False)\n",
    "            precisions, recalls = precision_recall_at_k(predictions, k=k, threshold=3.5)\n",
    "\n",
    "            # Precision and recall can then be averaged over all users\n",
    "            p.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "            r.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "        \n",
    "        print('>>> precision:', round(sum(p) / len(p), 3))\n",
    "        print('>>> reccall  :', round(sum(r) / len(r), 3))\n",
    "        print('\\n')           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Do you note anything interesting about these values? \n",
    "In random model increasing in two times of the number of clusters (k) leads to achieving high rates of precision and recall. What means, that this model predicts better with k = 10 instead of 5. Although, collaborative filtering models and matrix factorization method have other tendency. By increasing the number of clusters, the precisions of these models became less, as compared to the case, where k = 5. In comparison, recall rates behaved vice versa. When we set more clusters (10), recall values obtained higher points.\n",
    "#### 2. Anything differerent from the RMSE values you computed above?\n",
    "So RMSE is another type of metrics in comparison with precision and recall. In RMSE camputation, the best predictor was the matrix factorization method, as opposed to \"precision/recall\" metric, where in k = 5 user-based model achieved the highest precision (0.764) and recall (0.455). To compare RMSE with \"precision/recall\" metric (k=10), it is necessary to calculate RMSE for k =10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Top-`n` Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can see what some of the actual movie ratings are for particular users, as outputs of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we define a helpful function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=5):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = dict()\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        current = top_n.get(uid, [])\n",
    "        current.append((iid, est))\n",
    "        top_n[uid] = current\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we call this function on each of our models, first training on **all** the data we have available, then predicting on the remaining, missing data. We use `n`=5 here, but you can pick any reasonable value of `n` you would like.\n",
    "\n",
    "This may take some time to compute, so be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Use [`**Dataset.build_full_trainset**`](http://surprise.readthedocs.io/en/stable/dataset.html#surprise.dataset.DatasetAutoFolds.build_full_trainset) to get the full trainset from the data. Then call [`**Trainset.build_anti_testset**`](http://surprise.readthedocs.io/en/stable/trainset.html#surprise.Trainset.build_anti_testset) to get the testset out. Finally, `fit` on the trainset, `test` on the testset, then pass that result to our `get_top_n` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">QUESTION 5: TOP N PREDICTIONS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do the top n predictions that you received make sense? What is the rating value (1-5) of these predictions? How could you use these predictions in the real-world if you were trying to build a generic content recommender system for a company?**\n",
    "\n",
    "Some code is required for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: <surprise.prediction_algorithms.random_pred.NormalPredictor object at 0x7f6fa1cbd6a0>, 196: [('474', 5), ('387', 5), ('4', 5), ('100', 5), ('219', 5)]\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "model: <surprise.prediction_algorithms.knns.KNNBasic object at 0x7f6f849e3c18>, 196: [('1189', 5), ('1500', 5), ('814', 5), ('1536', 5), ('1599', 5)]\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "model: <surprise.prediction_algorithms.knns.KNNBasic object at 0x7f6fa1c84f28>, 196: [('1414', 4.666666666666667), ('1309', 4.5), ('1310', 4.5), ('1675', 4.333333333333333), ('1676', 4.3076923076923075)]\n",
      "model: <surprise.prediction_algorithms.matrix_factorization.SVD object at 0x7f6f85718cc0>, 196: [('127', 4.737397575904313), ('64', 4.728400472602509), ('511', 4.628932304627258), ('272', 4.520357278067382), ('318', 4.514511059057053)]\n",
      "\n",
      "\n",
      "Top N computation successful!\n"
     ]
    }
   ],
   "source": [
    "# Use the function and hints above to give the top-n predictions for a given user, for a reasonable value of n\n",
    "for model in models:\n",
    "    model.fit(trainset)\n",
    "    predictions = model.test(testset)\n",
    "    top_n = get_top_n(predictions, n=5)\n",
    "    # Print the first one\n",
    "    user = list(top_n.keys())[0]\n",
    "    print(f'model: {model}, {user}: {top_n[user]}')\n",
    "\n",
    "print('\\n\\nTop N computation successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Do the top n predictions that you received make sense? \n",
    "Yes, as for certain individual we have top 5 predictions of movies ratings calculated by 4 our methods. \n",
    "#### 2. What is the rating value (1-5) of these predictions?\n",
    "The random model and user-based CF achieved 5 out of 5 for 5 movies. As compared to other two methods (item-based and MF), which have the ratings, which are close to 4.5.\n",
    "#### 3. How could you use these predictions in the real-world if you were trying to build a generic content recommender system for a company?\n",
    "I suppose that these predictions could be beneficial in case when we recommend movies with high rating to other people who have the same rates for other movies. It means that when we predict ratings of new data (movies) for new people, we could base on the previous received movies ratings (same users behaviours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! Now, make sure you check out the **Conclusion** section of the [instruction manual](https://courses.edx.org/asset-v1:MITxPRO+DSx+2T2018+type@asset+block@4.1_instruction_manual.html) to wrap up this case study properly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
