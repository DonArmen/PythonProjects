# Python Projects
| File | Description | Tags |
| --- | --- | --- |
| |__Machine Learning__ ||
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/ArmenKhachatrianML1.ipynb) | House price of unit area prediction using the market historical data set of real estate valuation | `Linear Regression` `Supervised learning` `OLS` `R squared comparison` `Machine Learning`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/Armen_CS%20663_05_Hierarchical.ipynb) | Hierarchical clustering with NIPS Conference Papers dataset (1987 - 2015) | `Clustering` `Hierarchical clustering` `Unsupervised learning` `Machine Learning`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/CS%20663%20-%2003-PCA%20-%20Armen%20Khachatrian.ipynb) | Principal Component Analysis using Wisconsin Diagnosis Breast Cancer and Gisette datasets | `PCA` `Unsupervised learning` `Machine Learning`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/CS_ExtraLab.ipynb) | Linear Support Vector Classification and Gaussian Radial Basis Function with cross-validation | `SVM` `Support Vector Machines` `Supervised learning` `Machine Learning`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/Chicago_dataset.ipynb) | K-Means method for Chicago Dataset | `k-Means` `Unsupervised learning` `Machine Learning`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/DataChallengeFinal.ipynb) | Health Inspectors from the Health Department of the City and County of San Francisco routinely conduct inspections of restaurants (“facilities”). After conducting an inspection of a facility, a Health Inspector calculates a score based on the violations observed. Predict and explain inspection scores | `Random Forest Regressor` `GridSearchCV` `Supervised learning` `Machine Learning`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/FinnishData.ipynb) | K-Means method for Finnish Dataset | `k-Means` `Unsupervised learning` `Machine Learning`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/Khachatrian_knn.ipynb) | K-Nearest neighbors method for IRIS Dataset | `kNN` `K-Nearest neighbors` `Cross Validation` `Supervised learning` `Machine Learning`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/Lab5_LR_Statistical_Way_Armen_(Last_version).ipynb) | Predicting working hours for Toluca dataset. (Linear regression) Predicting Limit for Credit dataset (Linear Multiple regressions) - Statistical way| `Linear Regression` `Multiple regression`  `Supervised learning` `OLS` `Fvalue` `p_value` `R squared` `Machine Learning`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/Lab5_regression_Armen.ipynb) | Predicting working hours for Toluca dataset. (Linear regression) Predicting Limit for Credit dataset (Linear Multiple regressions) - scikit-learn| `Linear Regression` `Multiple regression`  `Supervised learning` `OLS` `Fvalue` `p_value` `R squared` `Machine Learning`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/MLhomework_adjusted.ipynb) | Binary and Multiclass Classification problems using Chicago Crime dataset (2010-2017)| `Binary Classification` `Multiclass Classification`  `Supervised learning` `Random Forest Classification` `Logistic Regression` `Machine Learning`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/TitanicCode.ipynb) | Show the difference in survival rates based on fare paid for Titanic dataset| `Outliers` `Boxplot`  `Distplot` `Machine Learning`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/advanced_python.ipynb) | Movie ratings. 4 Models: Random (NormalPredictor()),  User-Based Collaborative Filtering, Item-Based Collaborative Filtering, Matrix Factorization. Precision and Recall. Top-n predictions| `kNN` `SVD` `Supervised learning` `Cross Validation` `Precision` `Recall` `Machine Learning`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/advanced_python-3.ipynb) | NYC Taxi Trips. Models: Gradient Bossting Regressor. Compute features. Feature importances| `Unsupervised learning` `Feature importance` `Machine Learning`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/kmeans.ipynb) | Using class() manually write k-Means method| `Classes` `k-Means` `Unsupervised learning` `Machine Learning`|

| | __Advanced Online Experimentation__||

| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/Economics691_06_Assignment2.ipynb) | Heterogeneous Treatment Effects in spending too much, too little, or about the right amount on assistance to the poor/welfare based on age and political parties of the participants. DoorDash: linking of Venmo accounts to pay for meals. | `Heterogeneous Treatment Effects` `Non-Compliance` `Linear Regression` `Supervised learning` `OLS` `Bootstrap` `Per-Protocol estimator` `As-Treated estimator` `Intent-to-treat estimator`  `Wald estimator` `Weighted Wald estimator` `MinMaxScaler` `MSE` `Advanced Online Experimentation`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/Homework3_AdvExp.ipynb) | Calculate power for a standard experiment. Zynga: see how much revenue it earns from players with the new multi-player version | `Statistical power` `Surrogates` `Network Effects` `Person-level randomization` `City-level randomization` `Two-stage randomization` `Bootstrap` `Advanced Online Experimentation`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/Econ691-06_Assign4.ipynb) | Hello Fresh and Blue Apron: estimate a treatment effect (a low-sodium version of its meal plan).  Write a function that can compute the standard errors for the mean of a data series via 1000 bootstrapped iterations| `Quasi-Experimental Methods` `Event study` `Differences-in-differences analysis` `Regression discontinuity` `Instrumental variables approach` `Linear Regression` `Supervised learning` `OLS` `Bootstrap` `Streaming Bootstrap` `Advanced Online Experimentation`|
| | __Experiments and Causal Inference__||
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/Khachatrian_law_of_large_numbers.ipynb) | Modify the function to take an argument n_sequences and create that many separate replications of the sequence at once (Law of large numbers) | `Law of large numbers` `Experiments and Causal Inference`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/Khachatrian_selection_bias.ipynb) | Make a version of this data-generating process that is a true randomized experiment. Make a version of the biased data-generating process (calculate ATE and NATE) | `Selection Bias` `ATE` `NATE` `DGP` `Experiments and Causal Inference`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/PS_Sel_bias_Big_data.ipynb) | Make a function selection_bias(n) that calculates the selection bias in just the first n units of data ("sample size of n"). Try it for a few different values of n. Demonstrate that the law of large numbers applies to selection bias. Make a graph of bias for n ranging from 0 to 10,000.| `Selection Bias` `Big Data` `Treatment and Control Group` `Experiments and Causal Inference`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/Problemset2.ipynb) | Develop a portfolio of simulation, analytical, and graphical patterns for understanding random sampling and hypothesis tests.| `ATE` `Power` `False Positives` `t-test` `Treatment and Control Group` `Experiments and Causal Inference`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/Khachatrian_PS3.ipynb) | Reproducing results from a real field experiment and Classic blocking example: Shoe technology experiment | `ATE` `R packages in Python` `Treatment and Control Group` `Linear Regression` `DGP` `Blocking` `Karlan Experiment` `Statistical power` `Experiments and Causal Inference`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/Armen_KhachatrianPS4.ipynb) | The NATE (Naive Average Treatment Effect) decomposition, checking the independence assumption, calculating unbiased ATE via regression model, doing the "perfect stratification" analysis with modifying DGP (Data Generating Process) | `ATE` `NATE` `R packages in Python` `Treatment and Control Group` `Linear Regression` `DGP` `Perfect Stratification Analysis` `Independence Assumption` `Experiments and Causal Inference`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/ArmenKhachatrianProblemSet5.ipynb) | Understand how dependence in the hypothesis tests reduces power when we use the Bonferroni correction. Analyze the performance of the BH correction under high and low covariance. Simulating the "peeking" experiments'| `Bonferroni Correction` `Peeking Experiments` `Experiments and Causal Inference` |
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/ArmenKhachatrianPS6.ipynb) | A/B testing with finding an optimal alpha (significance level) level under different scenarios. Using R packages in Python, checking null hypotheses with calculating experiment cost, and null hypothesis significance testing (NHST)| `A/B testing` `R packages in Python` `Treatment and Control Group` `Experiments and Causal Inference` |
| | __Other__||
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/ChM_Armen_1.ipynb) | Numerical Methods: Euler method, Rectangle method,  Runge-Kutta 4th order method; calculating error | `Numerical Methods` `Euler method` `Rectangle method` `Runge-Kutta method`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/HW_Numerical_Methods.ipynb) | (1) Numerical Methods: Bisection method, Newton's method, Fixed-point iteration| `Numerical Methods` `Bisection method` `Newton's method` `Fixed-point iteration`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/KhachatrianAA_4L_NM.ipynb) | Numerical Methods: Newton's method| `Numerical Methods` `Newton's method`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/KhachatrianAA_5L_NM.ipynb) | Numerical Methods: Gaussian elimination, Gauss–Seidel method| `Numerical Methods` `Gaussian elimination` `Gauss–Seidel method`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/KhachatrianAA_8L_NM.ipynb) | Numerical Methods: Trapezoidal rule, Simpson's rule, Rectangle method| `Numerical Methods` `Trapezoidal rule` `Simpson's rule` `Rectangle method`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/KhachatrianAA_9L_NM.ipynb) | Numerical Methods: Newton's method - mathematical optimization| `Numerical Methods` `Newton's method` `Mathematical Optimization`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/KhachatrianAA_L6_NM.ipynb) | Numerical Methods: Generalized Least Squares, Ordinary Least Squares| `Numerical Methods` `Generalized Least Squares` `GLS` `Ordinary Least Squares` `OLS`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/Laba3NMKhachatrian.ipynb) | Numerical Methods: Matrices, Gaussian elimination | `Numerical Methods` `Gaussian elimination` `Matrices`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/NM_Lab2Armen.ipynb) | (2) Numerical Methods: Bisection method, Newton's method, Fixed-point iteration| `Numerical Methods` `Bisection method` `Newton's method` `Fixed-point iteration`|
| [Code.ipynb](https://github.com/akhachatrian/PythonProjects/blob/master/image_layers.ipynb) | Retrieve image layers to get the original picture| `Image Layers`|

