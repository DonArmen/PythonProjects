{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Econ 691-06\n",
    "### Assignment 6\n",
    "\n",
    "#### Armen Khachatrian\n",
    "##### Collaboration with Joseph Oon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Multi-Armed Bandits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AV  Club,  an  online  publisher  known  for  its  review  of  television  shows  and  movies,  is  debatingbetween two possible headlines for a short article.  Those two headlines are:\n",
    "\n",
    "* Why the last episode of The Simpsons left us with a cliffhanger\n",
    "* What the cliffhanger means for the next episode of The Simpsons\n",
    "\n",
    "In both cases, the articles are the same (reviewing the last episode and forecasting the next episode);but the headline can either advertise its commentary on the last episode or on the next one.  Forthe sake of notation, suppose the test is the first headline (the last episode) and the control is thesecond headline (the next episode).  AV Club wants to deploy a bandit to maximize time spentreading the article.The  response  functions  for  article  readers  is  below,  in  both  Python  and  R.  These  represent  theamount  of  time,  in  seconds,  that  readers  spend  reading  the  article.   Notice  that  the  responsefunction differ from the one discussed in class in one crucial dimension:  the response to treatmentchanges over time.  Early readers have a relatively positive reaction to the first headline comparedto  the  second  one,  while  later  readers  have  a  relatively  negative  reaction.   This  should  not  besurprising, given that the first headline focuses on the last episode and so does best right after theepisode has been aired; and the second headline focuses on the next episode and so does best rightbefore that episode is to be aired.  In this simulation, we will always assume there are five hundredreaders who come to the article, soiranges from 1 to 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. (5 points) In class, we covered three approaches:  the standard experiment (in which eachuser  is  independently  assigned  to  treatment  with  50%  probability),  the  constant-$\\epsilon$ bandit,and the declining-$\\epsilon$ bandit.  Include them in your code, and update them in two ways.  First,update both their defaultnand their calls to the individualresponse function.  Second, havethe functionsonlyreturn the average time-spent, in seconds, on the article.  This is becausethe coefficient and standard error are no longer useful attributes of the data, because of thevariation in the coefficient across time and across the order of units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import statsmodels.formula.api as sm\n",
    "from scipy.stats import ttest_ind\n",
    "#function\n",
    "def individual_response(treatment, i):\n",
    "    return(max(0, 12 + (5 - i/70) * treatment + np.random.normal(0, 5, 1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The treatment effect is: 1.8923\n"
     ]
    }
   ],
   "source": [
    "treatment_effect = (np.mean([individual_response(1, i) for i in range(500)]) - \n",
    "                    np.mean([individual_response(0, i) for i in range(500)]))\n",
    "print(\"The treatment effect is: \" + str(round(treatment_effect, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard experiment time-spent:  12.7345\n",
      "Constant epsilon bandit time-spent (default epsilon=0.01):  11.7717\n",
      "Decreasing epsilon bandit time-spent (default alpha=0.001):  12.7405\n"
     ]
    }
   ],
   "source": [
    "# Define function experiment\n",
    "def experiment(method = 'standard', n = 500, epsilon = 0.01, alpha = 0.001):\n",
    "    if method == 'standard': #standard experimentation\n",
    "        indicator = np.random.choice([0, 1], n, replace = True)\n",
    "        response = []\n",
    "        for i in range(n):\n",
    "            response.append(individual_response(indicator[i], i))\n",
    "\n",
    "        # response-treatment data\n",
    "        data = pd.DataFrame({'response': response, 'treatment': indicator})\n",
    "        #return average time-spent\n",
    "        return round(sum(data['response'])/n, 4)\n",
    "    \n",
    "    if method == 'constant epsilon': #constant epsilon bandit\n",
    "        response = np.array([])\n",
    "        indicator = np.array([])\n",
    "        for i in range(n):\n",
    "            if np.random.rand(1)[0] < epsilon: #one random number/'explore' phase\n",
    "                if np.random.rand(1)[0] < 0.5:\n",
    "                    treatment = 1\n",
    "                else:\n",
    "                    treatment = 0\n",
    "    \n",
    "                # Else implement 'exploit' phase, where we take the best arm (greedy)\n",
    "            else:\n",
    "                y1 = sum(response[indicator == 1])/(sum(indicator) + 0.001)\n",
    "                y2 = sum(response[indicator == 0])/(i - sum(indicator) + 0.001)\n",
    "                if y1 > y2:\n",
    "                    treatment = 1\n",
    "                else:\n",
    "                    treatment = 0\n",
    "    \n",
    "                # Get and save the individual's response\n",
    "            response = np.append(response, individual_response(treatment, i))\n",
    "            indicator = np.append(indicator, treatment)\n",
    "\n",
    "        \n",
    "        data = pd.DataFrame({'response': response, 'treatment': indicator})\n",
    "        #return average time-spent\n",
    "        return round(sum(data['response'])/n, 4)\n",
    "        \n",
    "    if method == 'decreasing epsilon': #decreasing epsilon bandit\n",
    "        response = np.array([])\n",
    "        indicator = np.array([])\n",
    "\n",
    "      # Iterate through each person\n",
    "        for i in range(n):\n",
    "            if np.random.rand(1)[0] < np.exp(-alpha * i): #threshold\n",
    "                if np.random.rand(1)[0] < 0.5:\n",
    "                    treatment = 1\n",
    "                else: \n",
    "                    treatment = 0\n",
    "            else:#exploit\n",
    "                y1 = sum(response[indicator == 1])/(sum(indicator) + 0.001)\n",
    "                y2 = sum(response[indicator == 0])/(i - sum(indicator) + 0.001)\n",
    "                if y1 > y2:\n",
    "                    treatment = 1\n",
    "                else:\n",
    "                    treatment = 0\n",
    "\n",
    "            response = np.append(response, individual_response(treatment, i))\n",
    "            indicator = np.append(indicator, treatment)\n",
    "\n",
    "        data = pd.DataFrame({'response': response, 'treatment': indicator})\n",
    "        #return average time-spent\n",
    "        return round(sum(data['response'])/n, 4)\n",
    "    \n",
    "    if method == 'thomson': #thomson sampling\n",
    "        response = np.array([])\n",
    "        indicator = np.array([])\n",
    "        for i in range(30): #“burn-in”  period  \n",
    "            if np.random.rand(1)[0] < 0.5:\n",
    "                treatment = 1\n",
    "            else:\n",
    "                treatment = 0\n",
    "            response = np.append(response, individual_response(treatment, i))\n",
    "            indicator = np.append(indicator, treatment)\n",
    "        for i in range(30, n):\n",
    "            a = response[indicator == 1] #the set of treated\n",
    "            b = response[indicator == 0] #the set of control\n",
    "            t, pval = ttest_ind(a, b, equal_var=False) #calculating t value and p value\n",
    "            p = norm.cdf(t) #converting t value to probability\n",
    "            if np.random.rand(1)[0] < p: #random value\n",
    "                treatment = 1\n",
    "            else:\n",
    "                treatment = 0\n",
    "            response = np.append(response, individual_response(treatment, i))\n",
    "            indicator = np.append(indicator, treatment)\n",
    "        data = pd.DataFrame({'response': response, 'treatment': indicator}) \n",
    "        #return average time-spent\n",
    "        return round(sum(data['response'])/n, 4)\n",
    "# Set seed and run experiment\n",
    "np.random.seed(10)\n",
    "print('Standard experiment time-spent: ', experiment())\n",
    "print('Constant epsilon bandit time-spent (default epsilon=0.01): ', experiment('constant epsilon'))\n",
    "print('Decreasing epsilon bandit time-spent (default alpha=0.001): ', experiment('decreasing epsilon'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2. (25 points) AV Club also wants to implement a bandit that utilizes Thompson sampling, and asks for your assistance. Implement one, using the hints and guidance below; and demonstratethat it works by running the function once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomson sampling time-spent:  13.4338\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "print('Thomson sampling time-spent: ', experiment('thomson'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 3. (10 points) Evaluate the constant-$\\epsilon$ algorithm under four parameterizations: $\\epsilon$= 0.5, $\\epsilon$= 0.3, $\\epsilon$= 0.1, and $\\epsilon$= 0.01.  To mitigate noise, run each parameterization on one hundred differentstreams of data, and take the average of the hundred runs per parameterization. Explain the results:  which $\\epsilon$ performs best, which $\\epsilon$ performs worst, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.062985000000001, 13.171197999999999, 13.14611, 12.503052000000002]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "mean_values = []\n",
    "epsilons = [0.5, 0.3, 0.1, 0.01]\n",
    "for eps in epsilons:\n",
    "    for _ in range(100):\n",
    "        lst.append(experiment(method = 'constant epsilon', n = 500, epsilon = eps))\n",
    "    mean_values.append(np.mean(lst)) \n",
    "    lst.clear()\n",
    "np.random.seed(10)\n",
    "mean_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** $\\epsilon$ = 0.3 performs the best as it gives us the highest average time on site per person. \n",
    "$\\epsilon$ = 0.01 performs the worse. \n",
    "This is the first if loop in our experiment function has the condition if np.random.rand(1)[0] < $\\epsilon$ and having 0.01 as our $\\epsilon$ is very aggressive, and we will go, in general, to the exploitation phase. We can explain it because the threshold ($\\epsilon$) is low enough (0.01). The fact that we ignore the exploration phase will cause that y1 is larger than y2 (choosing the best arm), and it leads that most of the observations will go to the treatment group. When $\\epsilon$ equals 0.3, we obtain the highest average time with a 30% probability of being explored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 4. (10 points) Evaluate  the  declining-$\\epsilon$ algorithm  under  three  parameterizations: $\\alpha$ =  0.01, $\\alpha$ = 0.005, and $\\alpha$ =  0.001.   To  mitigate  noise,  run  each  parameterization  on  one  hundred different  streams  of  data,  and  take  the  average  of  the  hundred  runs  per parameterization. Explain the results:  whichαperforms best, which $\\alpha$ performs worst, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.082727000000004, 12.924902000000001, 12.754246000000002]"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst2 = []\n",
    "mean_values2 = []\n",
    "alphas = [0.01, 0.005, 0.001]\n",
    "for alpha in alphas:\n",
    "    for _ in range(100):\n",
    "        lst2.append(experiment(method = 'decreasing epsilon', n = 500, alpha = alpha))\n",
    "    mean_values2.append(np.mean(lst2)) \n",
    "    lst2.clear()\n",
    "np.random.seed(10)\n",
    "mean_values2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** The best $\\alpha$ is 0.01 and the worst $\\alpha$ is 0.001. \n",
    "\n",
    "Going back to our experiment function the first if condition is np.random.rand(1)[0] < np.exp(-alpha * i)  the smaller the $\\alpha$ actually makes np.exp(-alpha*i) really close to 1 and that will mean that all our observations will only go through the exploration phase and the experiment will be no different from a standard experiment as no observations will go through the multi arm bandit section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 5. (5 points) Evaluate the four approaches:  the experiment, the best constant-$\\epsilon$ algorithm, the best declining-$\\epsilon$ algorithm, and Thompson sampling.  To mitigate noise, run each algorithm on one  hundred different streams of data, and take the average of the hundred runs per algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.7324, 13.1423, 13.1078, 13.3283])"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods = ['standard', 'constant epsilon', 'decreasing epsilon', 'thomson']\n",
    "lst3 = []\n",
    "mean_values3 = []\n",
    "for method in methods:\n",
    "    for _ in range(100):\n",
    "        lst3.append(experiment(method = method, epsilon = 0.3, alpha = 0.01))\n",
    "    mean_values3.append(np.mean(lst3)) \n",
    "    lst3.clear()\n",
    "np.random.seed(10)\n",
    "np.round(mean_values3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \\\n",
    "Standard Experiment: 12.7324 sec\\\n",
    "Constant-$\\epsilon$ bandit: 13.1423 sec\\\n",
    "Decreasing-$\\epsilon$ bandit: 13.1078 sec\\\n",
    "Thomson sampling: 13.3283 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 6. Using these results, answer the following questions comparing Thompson sampling to each of the algorithms in turn.\\\n",
    "    (a) (5 points) Compare Thompson sampling to the experiment.  Which performs betterand why?\\\n",
    "    (b) (5 points) Compare  Thompson  sampling  to  the  best  constant-$\\epsilon$ algorithm. Which performs better and why?\\\n",
    "    (c) (5 points) Compare  Thompson  sampling  to  the  best  declining-$\\epsilon$ algorithm.   Which performs better and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) The Thompson  sampling performs better standard experiment showing a 0.5 more seconds spent on site per user. This is because in a standard experiment we are unable to explore and exploit at the same time. Using the Thompson sampling method we are able to.  Due to the nature of this experiment the time frame is short, we do not have time to explore fist and exploit later. In this experiment which was defined by the `individual_response` function where early reader have positive reaction to the first heading and later readers have negative. With shifting parameters like this Thompson sampling will perform better.\n",
    "\n",
    "b) Between constant epsilon and thompson sampling, thompson sampling performs better. thompson sampling performs better because with the weighted arm approach, our observation converges to the  optimal arm over time and this weights can change depending on our observations.\n",
    "\n",
    "c) Between decreasing epsilon and thompson sampling, thompson sampling performs better. Since we have an environment that evolves over time, constant epsilon performs better than decreasing epsilon and that can be observed from our result. However, the reason why thompson sampling performs better is because with a changing environment like this experiment, a thompson sampling can adjust accordingly, but a decreasing epsilon method cannot go back to a high exploration mode once the underlying enivornment changes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
